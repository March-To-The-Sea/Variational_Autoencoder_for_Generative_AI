{"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"","display_name":""},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras import datasets\n(x_train,y_train), (x_test,y_test) = datasets.fashion_mnist.load_data()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(imgs):\n    imgs = imgs.astype(\"float32\") / 255.0\n    imgs = np.pad(imgs, ((0, 0), (2,2), (2, 2)), constant_values = 0.0)\n    imgs = np.expand_dims(imgs, -1)\n    return imgs\n\nx_train = preprocess(x_train)\nx_test = preprocess(x_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_input = layers.Input(\n    shape = (32, 32, 1), name = \"encoder_input\"\n)\n\nx = layers.Conv2D(32, (3, 3), strides = 2, activation = 'relu', padding = \"same\")(encoder_input)\nx = layers.Conv2D(64, (3, 3), strides = 2, activation = 'relu', padding = \"same\")(x)\nx = layers.Conv2D(128, (3, 3), strides 2, activation = 'relu', padding = \"same\")(x)\nshape_before_flattening = K.int_shape(x)[1:]\n\nx = layers.Flatten()(x)\nencoder_output = layers.Dense(2, name = \"encoder_output\")(x)\n\nencoder = models.Model(encoder_input, encoder_output)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder_input = layers.Input(shape = (2,), name = \"decoder_input\")\nx = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\nx = layers.Reshape(shape_before_flattening)(x)\nx = layers.Conv2DTranspose(\n    128, (3, 3), strides = 2, activation = 'relu', padding = \"same\"\n)(x)\nx = layers.Conv2DTranspose(\n    64, (3, 3), strides = 2, activation = 'relu', padding = \"same\"\n)(x)\nx = layers.Conv2DTranspose(\n    32, (3, 3), strides = 2, activation = 'relu', padding = \"same\"\n)(x)\ndecoder_output = layers.Conv2D(\n    1, (3, 3), strides = 1, activation = \"sigmoid\". padding = \"same\", name = \"decoder_output\"\n)(x)\n\ndecoder = models.Model(decoder_input, decoder_output)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder = Model(encoder_input, decoder(encoder_output))\n\nautoencoder.compile(optimizer = \"adam\", loss = \"binary_crossentropy\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.fit(\n    x_train,\n    x_train,\n    epochs = 5,\n    batch_size = 100,\n    shuffle = True,\n    validation_data = (x_test, x_test),\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_images = x_test[:5000]\npredictions = autoencoder.predict(example_images)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = encoder.predict(example_images)\n\nplt.figure(figsize = (8, 8))\nplt.scatter(embeddings[:, 0], embeddings[:, 1], c = \"black\", alpha = 0.5, s = 3)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mins, maxs = np.min(embeddings, axis = 0), np.max(embeddings, axis = 0)\nsample = np.random.uniform(mins, maxs, size = (18, 2))\nreconstructions = decoder.predict(sample)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Sampling(layers.Layer):\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = K.random_normal(shape = (batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder_input = layers.Input(\n    shape = (32, 32, 1), name = \"encoder_input\"\n)\n\nx = layers.Conv2D(32, (3, 3), strides = 2, activation = 'relu', padding = \"same\")(encoder_input)\nx = layers.Conv2D(64, (3, 3), strides = 2, activation = 'relu', padding = \"same\")(x)\nx = layers.Conv2D(128, (3, 3), strides 2, activation = 'relu', padding = \"same\")(x)\nshape_before_flattening = K.int_shape(x)[1:]\n\nx = layers.Flatten()(x)\nz_mean = layers.Dense(2, name = \"z_mean\")(x)\nz_log_var = layers.Dense(2, name = \"z_log_var\")(x)\nz = Sampling()([z_mean, z_log_var])\n\nencoder = models.Model(encoder_input, [z_mean, z_log_var, z], name = \"encoder\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VAE(models.Model):\n    def __init__(self, encoder, decoderm, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = metrics.Mean(name = \"total_loss\")\n        self.reconstruction_loss_tracker = metrics.Mean(name = \"reconstruction_loss\")\n        self.kl_loss_tracker = metrics,Mean(name = \"kl_loss\")\n\n        @property\n        def metrics(self):\n            return[\n                self.total_loss_tracker,\n                self.reconstruction_loss_tracker,\n                self.kl_loss_tracker\n            ]\n        \n        def call(self, inputs):\n            z_mean, z_log_var, z = encoder(inputs)\n            reconstruction = decoder(z)\n            return z_mean, z_log_var, reconstruction\n        \n        def train_step(self, data):\n            with tf.GradientTape() as tape:\n                z_mean, z_log_var, reconstruction = self(data)\n                reconstruction_loss = tf.reduce_mean(\n                    500\n                    * losses.binary_crossentropy(\n                        data, reconstruction, axis = (1, 2, 3)\n                    )\n                )\n                kl_loss = tf.reduce_mean(\n                    reduce_sum(\n                        - 0.5\n                        * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n                        axis = 1,\n                    )\n                )\n                total_loss = reconstruction_loss + kl_loss\n\n            grads = tape.gradient(total_loss, self.trainable_weights)\n            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n\n            self.total_loss_tracker.update_state(total_loss)\n            self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n            self.kl_loss_tracker.update_state(kl_loss)\n\n            return {m.name: m.result() for m in self.metrics}\n        \n        vae = VAE(encoder, decoder)\n        vae.compile(optimizer = \"adam\")\n        vae.fit(\n            train, epochs = 5, batch_size =100\n        )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_width, grid_height = (10, 3)\nz_sample = np.random.normal(size = (grid_width * grid_height, 200))\n\nreconstructions = decoder.predict(z_sample)\n\nfig = plt.figure(figsize = (18, 5))\nfig.subplogs_adjust(hspace = 0.4, wspace = 0.4)\nfor i in range(grid_width * grid_height):\n    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n    ax.axis(\"off\")\n    ax.imshow(reconstructions[i, :, :])","metadata":{},"execution_count":null,"outputs":[]}]}